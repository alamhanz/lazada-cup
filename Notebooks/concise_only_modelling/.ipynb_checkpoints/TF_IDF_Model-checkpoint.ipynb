{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF LAC 2017 (concise case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelling concise case of LAC 2017 use TF_IDF as word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aska\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Word2Vec\n",
    "import ast\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# for model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"../Data/Raw/\"\n",
    "DATA_PATH2=\"../..//Data/Manipulation/\"\n",
    "MODEL_PATH=\"../../Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_tr=pd.read_csv(DATA_PATH2+\"data_train_tokenize_concise_only2_train.csv\")\n",
    "dta_te=pd.read_csv(DATA_PATH2+\"data_train_tokenize_concise_only2_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_tr[\"true_text\"]=dta_tr.token_short_des.apply(lambda x: \" \".join(ast.literal_eval(x)))\n",
    "dta_te[\"true_text\"]=dta_te.token_short_des.apply(lambda x: \" \".join(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=dta_tr.true_text.tolist()\n",
    "docs_te=dta_te.true_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['formulated oil free hydrating botanicals remarkably improves skin texture abused hands restores soft smooth refined hands',\n",
       " '150cm mini microphone compatible iphone various smartphones also ipad apple computer macbook dual headed design allows two people using simultaneously features high sensitivity omni directional sounds output perfect audio video recording 3 5mm standard connector jack convenient clip design clip collar 3 5mm standard connector jack convenient clip design clip collar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_trans_75=TfidfVectorizer(max_features=75)\n",
    "tfidf_trans_75.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_trans_150=TfidfVectorizer(max_features=150)\n",
    "tfidf_trans_150.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_trans_225=TfidfVectorizer(max_features=225)\n",
    "tfidf_trans_225.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=tfidf_trans_75.transform([docs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57384093, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.607389  , 0.        , 0.54934979,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Models/tfidf225_transform.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_trans_75,MODEL_PATH+\"tfidf75_transform.pkl\")\n",
    "joblib.dump(tfidf_trans_150,MODEL_PATH+\"tfidf150_transform.pkl\")\n",
    "joblib.dump(tfidf_trans_225,MODEL_PATH+\"tfidf225_transform.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=8\n",
    "BATCH=590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_model(input_size):\n",
    "    model = Sequential()\n",
    "#     model.add(Embedding(50, 12, input_length=input_size))\n",
    "    \n",
    "#     Embedding(vocab_size, embd2.layer1_size, weights=[embedding_vectors], \n",
    "#                             input_length=max_length, trainable=False)\n",
    "    \n",
    "#     model.add(Conv1D(filters=8, kernel_size=5, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3))\n",
    "#     model.add(Flatten())\n",
    "    model.add(Dense(200,input_dim=input_size, activation='relu'))\n",
    "    model.add(Dense(200,input_dim=input_size, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(70, activation='relu'))\n",
    "    model.add(Dense(70, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true=dta_tr[\"conci\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X75=tfidf_trans_75.transform(dta_tr.true_text)\n",
    "X150=tfidf_trans_150.transform(dta_tr.true_text)\n",
    "X225=tfidf_trans_225.transform(dta_tr.true_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 200)               15200     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 70)                14070     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                1065      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 75,761\n",
      "Trainable params: 75,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model 75\n",
    "model75=cur_model(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_logger = CSVLogger(DATA_PATH2+'log75.csv', append=True, separator=',')\n",
    "model75.fit(X75, Y_true, epochs=EPOCH, batch_size=BATCH,verbose=0,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model 150\n",
    "model150=cur_model(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_logger = CSVLogger(DATA_PATH2+'log150.csv', append=True, separator=',')\n",
    "model150.fit(X150, Y_true, epochs=EPOCH, batch_size=BATCH,verbose=0,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model 225\n",
    "model225=cur_model(225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_logger = CSVLogger(DATA_PATH2+'log225.csv', append=True, separator=',')\n",
    "model225.fit(X225, Y_true, epochs=EPOCH, batch_size=BATCH,verbose=0,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving\n",
    "\n",
    "# serialize model to JSON\n",
    "for model,mod_name in [(model75,\"tfidf_model75\"),(model150,\"tfidf_model150\"),(model225,\"tfidf_model225\")]:\n",
    "    model_json = model.to_json()\n",
    "    with open(MODEL_PATH+mod_name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(MODEL_PATH+mod_name+\"_weight.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,X in [(model75,X75),(model150,X150),(model225,X225)]:\n",
    "    loss, acc = model.evaluate(X, Y_true, verbose=0)\n",
    "    print('Train Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X75_te=tfidf_trans_75.transform(dta_te.true_text)\n",
    "X150_te=tfidf_trans_150.transform(dta_te.true_text)\n",
    "X225_te=tfidf_trans_225.transform(dta_te.true_text)\n",
    "\n",
    "Y_test=dta_te.conci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,X in [(model75,X75_te),(model150,X150_te),(model225,X225_te)]:\n",
    "    loss, acc = model.evaluate(X, Y_test, verbose=0)\n",
    "    print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 630"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
