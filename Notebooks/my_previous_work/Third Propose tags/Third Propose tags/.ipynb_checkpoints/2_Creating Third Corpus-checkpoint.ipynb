{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\n",
    "\n",
    "## https://github.com/aboSamoor/polyglot/issues/80\n",
    "# conda install -c conda-forge pyicu morfessor icu -y && pip install pycld2 polyglot\n",
    "\n",
    "\n",
    "# polyglot download TASK:ner2\n",
    "# polyglot download TASK:embeddings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../../data/'\n",
    "data_raw_path=\"../../data/raw/for third propose/\"\n",
    "data_man_path=\"../../data/manipulate/for third propose/\"\n",
    "model_path=\"../../model/modeling_third_propose/\"\n",
    "w2v_path=\"../../data/w2v/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from string import digits\n",
    "import ast\n",
    "\n",
    "import polyglot\n",
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://polyglot.readthedocs.io/en/latest/Embeddings.html\n",
    "from polyglot.mapping import Embedding\n",
    "from polyglot.mapping import CaseExpander, DigitExpander\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_id=open(data_path+\"stopwords_id.txt\")\n",
    "stop_words_id=list(set([i[:-1] for i in stop_words_id.readlines()]))\n",
    "\n",
    "stop_words_en=open(data_path+\"stopwords_en.txt\")\n",
    "stop_words_en=list(set([i[:-1] for i in stop_words_en.readlines()]))\n",
    "\n",
    "stop_words=stop_words_id+stop_words_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_add=['nambah', 'byk', 'yaaa', 'ksh', 'bs', 'kl', 'sm', 'smua',\n",
    "       'seadanya', 'ajh', 'atau', 'mnta', 'klw', 'ato', 'kalo', 'abis',\n",
    "       'bnyk', 'pokoknya', 'jgn', 'smuanya', 'klo', 'gitu', 'yaaaa',\n",
    "       'gpp', 'disitu', 'aj', 'hehe', 'jg', 'yng', 'ya', 'habis', 'gada',\n",
    "       'ajaa', 'klu', 'ush', 'terserah', 'yah', 'salah', 'brp', 'yaa',\n",
    "       'aja', 'trs', 'tambahin', 'nya', 'tp', 'ajah', 'mnt', 'situ',\n",
    "       'segitu', 'disatuin', 'satuin', 'gapapa', 'yg', 'gabung', 'trus',\n",
    "       'biar', 'nyaa', 'klau', 'lbh']\n",
    "stop_words2=stop_words+stop_word_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get The Data and create our word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.W7MeoBMzY3E\n",
    "# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "# https://github.com/RaRe-Technologies/gensim/issues/814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_one_stops(X):\n",
    "    X2=[]\n",
    "    for c in X:\n",
    "        if len(c)>=2 and c not in stop_words2:\n",
    "            X2.append(c)\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# dtext=pd.read_csv(data_raw_path+\"data_text_goshop_2.csv\")\n",
    "# dtag=pd.read_csv(data_raw_path+\"data_tag_goshop.csv\")\n",
    "\n",
    "dtext2=pd.read_csv(data_man_path+\"data_gocommerce_items_sample_1_cln_w_label3.csv\")\n",
    "dtext2[\"real_tags\"]=dtext2.real_tags.apply(lambda x : set(ast.literal_eval(x)))\n",
    "# dtag=pd.read_csv(data_man_path+\"data_tag_goshop2.csv\")\n",
    "# dtag.to_csv(data_man_path+\"data_tag_goshop2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtext2_food=dtext2[dtext2.type==\"food\"][[\"item_list_cln2\",\"merchant_name_cln1\",\"type\"]]\n",
    "dtext2_non_food=dtext2[dtext2.type!=\"food\"][[\"item_list_cln2\",\"merchant_name_cln1\",\"type\"]]\n",
    "\n",
    "dtext2_food[\"sentence_used\"]=dtext2_food.item_list_cln2+\" \"+dtext2_food.merchant_name_cln1\n",
    "# dtext2_food[\"sentence_used\"]=dtext2_food.item_list_cln2\n",
    "dtext2_non_food[\"sentence_used\"]=dtext2_non_food.item_list_cln2\n",
    "\n",
    "dtext3=pd.concat([dtext2_food,dtext2_non_food])\n",
    "# dtext3=pd.concat([dtext2_non_food])\n",
    "# dtext3=dtext2_non_food[dtext2_non_food.type==\"shop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_list_cln2</th>\n",
       "      <th>merchant_name_cln1</th>\n",
       "      <th>type</th>\n",
       "      <th>sentence_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2799998</th>\n",
       "      <td>nasi paket ayam geprek</td>\n",
       "      <td>geprek bensu</td>\n",
       "      <td>food</td>\n",
       "      <td>nasi paket ayam geprek geprek bensu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799999</th>\n",
       "      <td>bakso mukidi</td>\n",
       "      <td>mie ayam bakso mukidi</td>\n",
       "      <td>food</td>\n",
       "      <td>bakso mukidi mie ayam bakso mukidi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800000</th>\n",
       "      <td>italian meat ball stuffed crust regular chessy...</td>\n",
       "      <td>phd</td>\n",
       "      <td>food</td>\n",
       "      <td>italian meat ball stuffed crust regular chessy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800001</th>\n",
       "      <td>nasi bebek</td>\n",
       "      <td>bebek sinjay</td>\n",
       "      <td>food</td>\n",
       "      <td>nasi bebek bebek sinjay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800002</th>\n",
       "      <td>salted egg chicken</td>\n",
       "      <td>sec bowl by rius vernandes</td>\n",
       "      <td>food</td>\n",
       "      <td>salted egg chicken sec bowl by rius vernandes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            item_list_cln2  \\\n",
       "2799998                             nasi paket ayam geprek   \n",
       "2799999                                       bakso mukidi   \n",
       "2800000  italian meat ball stuffed crust regular chessy...   \n",
       "2800001                                         nasi bebek   \n",
       "2800002                                 salted egg chicken   \n",
       "\n",
       "                 merchant_name_cln1  type  \\\n",
       "2799998                geprek bensu  food   \n",
       "2799999       mie ayam bakso mukidi  food   \n",
       "2800000                         phd  food   \n",
       "2800001                bebek sinjay  food   \n",
       "2800002  sec bowl by rius vernandes  food   \n",
       "\n",
       "                                             sentence_used  \n",
       "2799998                nasi paket ayam geprek geprek bensu  \n",
       "2799999                 bakso mukidi mie ayam bakso mukidi  \n",
       "2800000  italian meat ball stuffed crust regular chessy...  \n",
       "2800001                            nasi bebek bebek sinjay  \n",
       "2800002      salted egg chicken sec bowl by rius vernandes  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtext3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=[]\n",
    "# for il in dtext2.sample(15,random_state=100).item_list_cln2.tolist()[:10]:\n",
    "for il in dtext3[~(dtext3.sentence_used.isnull())].sentence_used.tolist():\n",
    "    il2=il.split(\" \")\n",
    "#     sentence.append(il2)\n",
    "    il3=remove_one_stops(il2)\n",
    "    sentence.append(il3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3599510"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_emb = Word2Vec(sentence,size=100,\n",
    "#         window=8,min_count=60,workers=5)\n",
    "model_emb = Word2Vec(sentence,size=90,\n",
    "        window=8,min_count=40,workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234761421, 279159060)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb.train(sentence, total_examples=len(sentence), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.11427715,  1.6115043 ,  0.78236306, -1.6907134 , -0.24915132,\n",
       "        0.35412213,  0.79163283,  0.14339279, -1.6021619 ,  0.9053349 ,\n",
       "       -0.27305898, -1.5851066 ,  1.3857781 , -1.9324019 ,  0.53924507,\n",
       "        0.36737087,  0.4550265 ,  3.6157942 , -2.0297515 , -3.0608616 ,\n",
       "       -0.5734429 , -0.39045066,  0.24151619, -1.8992816 , -0.5449692 ,\n",
       "       -1.7906028 , -0.91664904,  3.4364398 ,  1.3262398 , -1.6691551 ,\n",
       "       -1.9648712 ,  0.49161977, -1.8834251 , -2.130431  , -0.7933773 ,\n",
       "       -1.0450284 , -0.45371664,  0.6407101 ,  0.38878283, -2.360629  ,\n",
       "        1.3636858 ,  2.4583175 ,  0.16506055, -1.0984727 ,  0.78420293,\n",
       "        1.0610428 , -0.6237064 ,  1.0974616 ,  1.0192817 , -2.2474856 ,\n",
       "       -0.7491692 , -0.06259245, -1.4241807 ,  1.8909247 , -0.5780439 ,\n",
       "        1.060845  ,  1.742925  , -0.22930385,  0.9235678 , -0.17818184,\n",
       "        2.8464372 ,  1.1480416 , -0.5466136 , -0.8700628 , -1.7159238 ,\n",
       "        2.2271917 ,  0.9053491 , -1.450653  , -3.408193  , -0.46094552,\n",
       "       -1.1811391 ,  1.5923383 , -0.04048454, -2.7839913 ,  2.7006211 ,\n",
       "        0.10594671, -1.4883412 ,  0.1263038 , -0.76816523, -1.9126616 ,\n",
       "       -1.5008037 ,  1.1673359 , -2.728107  ,  2.730935  ,  1.1124722 ,\n",
       "       -0.4582677 , -3.0106416 ,  2.0936153 , -3.1701705 ,  0.6808211 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb[\"remote\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ayan', 0.622320294380188),\n",
       " ('atam', 0.5937215089797974),\n",
       " ('aym', 0.5900243520736694),\n",
       " ('porsiayam', 0.5772808194160461),\n",
       " ('goreng', 0.5650893449783325),\n",
       " ('bungkusayam', 0.5523208379745483),\n",
       " ('nasi', 0.5451222658157349),\n",
       " ('komplit', 0.5297495126724243),\n",
       " ('porsi', 0.52732914686203),\n",
       " ('paha', 0.492574006319046),\n",
       " ('usus', 0.49121272563934326),\n",
       " ('ayamgoreng', 0.48943841457366943),\n",
       " ('rebus', 0.4858480989933014),\n",
       " ('potongayam', 0.4856860637664795),\n",
       " ('sapi', 0.46591830253601074),\n",
       " ('kuah', 0.46457886695861816),\n",
       " ('babi', 0.46023789048194885),\n",
       " ('terong', 0.4584827721118927),\n",
       " ('nasiputih', 0.4578687250614166),\n",
       " ('bebek', 0.44995731115341187)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [k[0] for k in model_emb.wv.most_similar(positive=\"babi\",topn=20)]\n",
    "model_emb.wv.most_similar(positive=\"ayam\",topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3148526"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb.wv.similarity(w1=\"ayam\",w2=\"chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb.save(w2v_path+'our_vocab3_w_merchant.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_chick=0\n",
    "for ss in sentence:\n",
    "    ww=\" \".join(ss)\n",
    "    if \"chicken\" in ww:\n",
    "        c_chick+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123928"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_chick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
