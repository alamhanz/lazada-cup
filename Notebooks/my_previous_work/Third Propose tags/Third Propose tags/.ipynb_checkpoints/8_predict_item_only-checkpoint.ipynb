{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get The Data Item Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../../data/'\n",
    "data_raw_path=\"../../data/raw/for third propose/\"\n",
    "data_man_path=\"../../data/manipulate/for third propose/\"\n",
    "model_path=\"../../model/modeling_third_propose/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dtesting=pd.read_csv(data_man_path+\"test_gocommerce_items_only_cln.csv\")\n",
    "dtag=pd.read_csv(data_man_path+\"data_tag_goshop3_unique.csv\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtesting2=dtesting[~(dtesting.item_list_cln1.isnull())]\n",
    "dtesting2=dtesting2[~(dtesting2.item_list_cln2.isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label with real (rule based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtag[\"num_word\"]=dtag.Keywords.apply(lambda x : len(x.split(\" \")))\n",
    "dtag[\"num_word_tag\"]=dtag.Tags.apply(lambda x : len(x.split(\" \")))\n",
    "\n",
    "keyword_set=set(dtag.Keywords.unique())\n",
    "keyword_set1=set([t for t in keyword_set if len(t.split(\" \"))==1])\n",
    "keyword_set2=set([t for t in keyword_set if len(t.split(\" \"))==2])\n",
    "keyword_set3=set([t for t in keyword_set if len(t.split(\" \"))==3])\n",
    "\n",
    "\n",
    "ts=set(dtag.Tags.unique())\n",
    "ts1=set([t for t in ts if len(t.split(\" \"))==1])\n",
    "ts2=set([t for t in ts if len(t.split(\" \"))==2])\n",
    "ts3=set([t for t in ts if len(t.split(\" \"))==3])\n",
    "\n",
    "dict_keyword=pd.DataFrame(dtag.Tags)\n",
    "dict_keyword.index=dtag.Keywords\n",
    "dict_keyword=dict_keyword[\"Tags\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_tags(X,Y):\n",
    "    X2=[]\n",
    "    for x1 in X:\n",
    "        k=0\n",
    "        for y1 in Y:\n",
    "            if x1 in y1:\n",
    "                k=1\n",
    "                break\n",
    "        if k==0:\n",
    "            X2.append(x1)\n",
    "    \n",
    "    return set(X2)|Y\n",
    "\n",
    "def remove_term(text,X):\n",
    "    for term in X:\n",
    "        text=text.replace(' '+term+' ',\" \")\n",
    "        text=re.sub( '\\s+', ' ',text)\n",
    "    return text\n",
    "    \n",
    "\n",
    "def tags(tx):\n",
    "    X3=set([tg for tg in keyword_set3 if ' '+tg+' ' in ' '+tx+' '])\n",
    "    tx2=remove_term(' '+tx+' ',X3)\n",
    "    X3=set([dict_keyword[t] for t in X3])\n",
    "    \n",
    "    X2=set([tg for tg in keyword_set2 if ' '+tg+' ' in ' '+tx2+' '])\n",
    "    tx3=remove_term(' '+tx2+' ',X2)\n",
    "    X2=set([dict_keyword[t] for t in X2])\n",
    "\n",
    "    X1=keyword_set1&set(tx3.split(\" \"))\n",
    "    X1=set([dict_keyword[t] for t in X1])\n",
    "    \n",
    "    X_tags0=X1|X2|X3\n",
    "    \n",
    "    T1=set([t for t in X_tags0 if len(t.split(\" \"))==1])\n",
    "    T2=set([t for t in X_tags0 if len(t.split(\" \"))==2])\n",
    "    T3=set([t for t in X_tags0 if len(t.split(\" \"))==3])\n",
    "    \n",
    "    T12=include_tags(T1,T2)\n",
    "    X_tags=include_tags(T12,T3)\n",
    "    \n",
    "    return X_tags\n",
    "\n",
    "def tags_mult(X):\n",
    "    XX=X.split(\",\")\n",
    "    tg_X=set([])\n",
    "    for t in XX:\n",
    "        if len(t)>=3:\n",
    "            t2=t.strip()\n",
    "            tg_X=tg_X|tags(t2)\n",
    "            \n",
    "    return tuple(tg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dtesting2.item_list_cln2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skmultilearn.problem_transform import LabelPowerset,ClassifierChain\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL2 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer_DL2=joblib.load(model_path+\"multilabel_bin_for_DL2.pkl\")\n",
    "tokenizer_DL2=joblib.load(model_path+\"tokenizer_for_DL2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform\n",
    "# sequence encode\n",
    "encoded_docs_DL2 = tokenizer_DL2.texts_to_sequences(X)\n",
    "# pad sequences\n",
    "max_length = 80\n",
    "X2_DL2 = pad_sequences(encoded_docs_DL2, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open(model_path+\"wv_DL2.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "DL2_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "DL2_model.load_weights(model_path+\"wv_DL2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "DL2_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DL2 = DL2_model.predict(X2_DL2) #Benchmark 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(yp,a=0.22):\n",
    "    YY=(yp>a).astype(int)\n",
    "    while YY.sum()==0 and a>=0.35:\n",
    "        a=a-0.02\n",
    "        YY=(yp>a).astype(int)\n",
    "    return YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2_DL2=np.array([transform_y(yp,a=0.55) for yp in y_pred_DL2])\n",
    "dtesting2[\"pred_tag_DL2\"]=multilabel_binarizer_DL2.inverse_transform(y_pred2_DL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dl2=open(model_path+\"good_tags_DL2.txt\",'r')\n",
    "gt_DL2=gt_dl2.readline().split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_DL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtesting2.to_csv(data_man_path+\"model_result_on_item_only_testing.csv\",index=False)\n",
    "# dtesting2=pd.read_csv(data_man_path+\"model_result_on_data_testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_list</th>\n",
       "      <th>real_tags</th>\n",
       "      <th>pred_tag_DL1</th>\n",
       "      <th>pred_tag_DL2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>793122</th>\n",
       "      <td>alfamidi pandan wangi 5 kg beras</td>\n",
       "      <td>(beras, alfamidi)</td>\n",
       "      <td>(alfamidi, beras)</td>\n",
       "      <td>(alfamidi, beras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353405</th>\n",
       "      <td>charger iphone</td>\n",
       "      <td>(charger,)</td>\n",
       "      <td>(charger,)</td>\n",
       "      <td>(charger,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997735</th>\n",
       "      <td>3 porsi bakso + keroket 10 (bakso dkt jasaraha...</td>\n",
       "      <td>(bakso,)</td>\n",
       "      <td>(bakso,)</td>\n",
       "      <td>(bakso,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918670</th>\n",
       "      <td>aqua air mineral 24 pcs x 600 ml</td>\n",
       "      <td>(aqua, air)</td>\n",
       "      <td>(air, aqua)</td>\n",
       "      <td>(air, aqua)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226595</th>\n",
       "      <td>piatos sapi panggang,amidis - 600 ml,sprite - ...</td>\n",
       "      <td>(frestea jasmine, piatos, tim tam, amidis, spr...</td>\n",
       "      <td>(frestea, frestea jasmine, tim tam)</td>\n",
       "      <td>(frestea, frestea jasmine, sprite, tim tam)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>beliin hp samsunbg S200</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>(charger,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>nasi + ayam geprek</td>\n",
       "      <td>(nasi, ayam geprek)</td>\n",
       "      <td>(ayam geprek, nasi)</td>\n",
       "      <td>(ayam geprek, nasi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45217</th>\n",
       "      <td>nasi goreng gila,kwetiaw goreng spesial</td>\n",
       "      <td>(nasi goreng, kwetiau)</td>\n",
       "      <td>(nasi goreng,)</td>\n",
       "      <td>(kwetiau, nasi goreng)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786418</th>\n",
       "      <td>aqua pet 600 ml mineral water,aqua pet 1 5 l m...</td>\n",
       "      <td>(aqua, air, formula)</td>\n",
       "      <td>(air, aqua)</td>\n",
       "      <td>(air, aqua, formula)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534762</th>\n",
       "      <td>nasi gemuk 4 bungkus (8.000), lupis 4 buah (2....</td>\n",
       "      <td>(nasi, buah)</td>\n",
       "      <td>(buah, nasi)</td>\n",
       "      <td>(buah, nasi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288681</th>\n",
       "      <td>mamy poko pants standar l x 8 pcs</td>\n",
       "      <td>(celana, mamy poko)</td>\n",
       "      <td>(celana, mamy poko)</td>\n",
       "      <td>(celana, mamy poko)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122820</th>\n",
       "      <td>nasi balado daging</td>\n",
       "      <td>(daging, nasi)</td>\n",
       "      <td>(daging, nasi)</td>\n",
       "      <td>(daging, nasi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313773</th>\n",
       "      <td>beli pakan lele 1sak/30kg kode 781-2</td>\n",
       "      <td>(lele,)</td>\n",
       "      <td>(lele,)</td>\n",
       "      <td>(lele,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111631</th>\n",
       "      <td>burger patties saus bolognese,french fries,ane...</td>\n",
       "      <td>(kentang goreng, burger, jus)</td>\n",
       "      <td>(burger, jus, kentang goreng)</td>\n",
       "      <td>(burger, kentang goreng, spaghetti)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917641</th>\n",
       "      <td>prime l organic tomat  - 1000 gr,paha utuh aya...</td>\n",
       "      <td>(strawberry, buavita, ayam kampung, sari roti,...</td>\n",
       "      <td>(ayam, buavita, sari roti)</td>\n",
       "      <td>(ayam kampung, buavita, fanta, strawberry)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item_list  \\\n",
       "793122                   alfamidi pandan wangi 5 kg beras   \n",
       "353405                                     charger iphone   \n",
       "997735  3 porsi bakso + keroket 10 (bakso dkt jasaraha...   \n",
       "918670                   aqua air mineral 24 pcs x 600 ml   \n",
       "226595  piatos sapi panggang,amidis - 600 ml,sprite - ...   \n",
       "664102                            beliin hp samsunbg S200   \n",
       "13998                                  nasi + ayam geprek   \n",
       "45217             nasi goreng gila,kwetiaw goreng spesial   \n",
       "786418  aqua pet 600 ml mineral water,aqua pet 1 5 l m...   \n",
       "534762  nasi gemuk 4 bungkus (8.000), lupis 4 buah (2....   \n",
       "288681                  mamy poko pants standar l x 8 pcs   \n",
       "122820                                 nasi balado daging   \n",
       "313773               beli pakan lele 1sak/30kg kode 781-2   \n",
       "111631  burger patties saus bolognese,french fries,ane...   \n",
       "917641  prime l organic tomat  - 1000 gr,paha utuh aya...   \n",
       "\n",
       "                                                real_tags  \\\n",
       "793122                                  (beras, alfamidi)   \n",
       "353405                                         (charger,)   \n",
       "997735                                           (bakso,)   \n",
       "918670                                        (aqua, air)   \n",
       "226595  (frestea jasmine, piatos, tim tam, amidis, spr...   \n",
       "664102                                                 ()   \n",
       "13998                                 (nasi, ayam geprek)   \n",
       "45217                              (nasi goreng, kwetiau)   \n",
       "786418                               (aqua, air, formula)   \n",
       "534762                                       (nasi, buah)   \n",
       "288681                                (celana, mamy poko)   \n",
       "122820                                     (daging, nasi)   \n",
       "313773                                            (lele,)   \n",
       "111631                      (kentang goreng, burger, jus)   \n",
       "917641  (strawberry, buavita, ayam kampung, sari roti,...   \n",
       "\n",
       "                               pred_tag_DL1  \\\n",
       "793122                    (alfamidi, beras)   \n",
       "353405                           (charger,)   \n",
       "997735                             (bakso,)   \n",
       "918670                          (air, aqua)   \n",
       "226595  (frestea, frestea jasmine, tim tam)   \n",
       "664102                                   ()   \n",
       "13998                   (ayam geprek, nasi)   \n",
       "45217                        (nasi goreng,)   \n",
       "786418                          (air, aqua)   \n",
       "534762                         (buah, nasi)   \n",
       "288681                  (celana, mamy poko)   \n",
       "122820                       (daging, nasi)   \n",
       "313773                              (lele,)   \n",
       "111631        (burger, jus, kentang goreng)   \n",
       "917641           (ayam, buavita, sari roti)   \n",
       "\n",
       "                                       pred_tag_DL2  \n",
       "793122                            (alfamidi, beras)  \n",
       "353405                                   (charger,)  \n",
       "997735                                     (bakso,)  \n",
       "918670                                  (air, aqua)  \n",
       "226595  (frestea, frestea jasmine, sprite, tim tam)  \n",
       "664102                                   (charger,)  \n",
       "13998                           (ayam geprek, nasi)  \n",
       "45217                        (kwetiau, nasi goreng)  \n",
       "786418                         (air, aqua, formula)  \n",
       "534762                                 (buah, nasi)  \n",
       "288681                          (celana, mamy poko)  \n",
       "122820                               (daging, nasi)  \n",
       "313773                                      (lele,)  \n",
       "111631          (burger, kentang goreng, spaghetti)  \n",
       "917641   (ayam kampung, buavita, fanta, strawberry)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtesting2[[\"item_list\",\"real_tags\",\"pred_tag_DL1\",\"pred_tag_DL2\"]].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.40515021459225"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((dd_eval_DL2.AUC>0.8)&(dd_eval_DL2[\"learn_rate(%)\"]>0)).mean()*451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.999401</td>\n",
       "      <td>0.895786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.051804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.988536</td>\n",
       "      <td>0.800310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.999278</td>\n",
       "      <td>0.852051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.896151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.939440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.998650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy         AUC\n",
       "count  652.000000  652.000000\n",
       "mean     0.999401    0.895786\n",
       "std      0.000837    0.051804\n",
       "min      0.988536    0.800310\n",
       "25%      0.999278    0.852051\n",
       "50%      0.999652    0.896151\n",
       "75%      0.999819    0.939440\n",
       "max      0.999993    0.998650"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_eval_DL2[(dd_eval_DL2.AUC>0.8)&(dd_eval_DL2[\"learn_rate(%)\"]>0)][[\"accuracy\",\"AUC\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booking_time</th>\n",
       "      <th>order_no</th>\n",
       "      <th>payment_method_name</th>\n",
       "      <th>merchant_name</th>\n",
       "      <th>type</th>\n",
       "      <th>item_list</th>\n",
       "      <th>item_list_cln1</th>\n",
       "      <th>item_list_cln2</th>\n",
       "      <th>real_tags</th>\n",
       "      <th>pred_tag_DL1</th>\n",
       "      <th>pred_tag_DL2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-30 01:00:58.129129</td>\n",
       "      <td>F-103656423</td>\n",
       "      <td>FREE</td>\n",
       "      <td>Soto Cemorojajar</td>\n",
       "      <td>food</td>\n",
       "      <td>mendoan</td>\n",
       "      <td>mendoan</td>\n",
       "      <td>mendoan</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-16 04:44:07.947744</td>\n",
       "      <td>F-94443846</td>\n",
       "      <td>PAY_LATER</td>\n",
       "      <td>Warung Sate Solo Pak Hadi</td>\n",
       "      <td>food</td>\n",
       "      <td>sate ayam,tongseng ayam</td>\n",
       "      <td>sate ayam,tongseng ayam</td>\n",
       "      <td>sate ayam tongseng ayam</td>\n",
       "      <td>(tongseng, ayam, sate ayam)</td>\n",
       "      <td>(ayam, sate ayam, tongseng)</td>\n",
       "      <td>(ayam, sate ayam, tongseng)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-11 05:39:01.530242</td>\n",
       "      <td>F-14238997</td>\n",
       "      <td>FREE</td>\n",
       "      <td>HokBen</td>\n",
       "      <td>food</td>\n",
       "      <td>hoka hemat 1</td>\n",
       "      <td>hoka hemat</td>\n",
       "      <td>hoka hemat</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-24 11:40:54.184264</td>\n",
       "      <td>F-100085239</td>\n",
       "      <td>PAY_LATER</td>\n",
       "      <td>Shukufuku Japanese StreetFood</td>\n",
       "      <td>food</td>\n",
       "      <td>gyu zuke</td>\n",
       "      <td>gyu zuke</td>\n",
       "      <td>gyu zuke</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-19 11:00:09.280537</td>\n",
       "      <td>F-96640563</td>\n",
       "      <td>PAY_LATER</td>\n",
       "      <td>Ayam Santai</td>\n",
       "      <td>food</td>\n",
       "      <td>paket ayam geprek nasi putih sambal korek pedas</td>\n",
       "      <td>paket ayam geprek nasi putih sambal korek pedas</td>\n",
       "      <td>paket ayam geprek nasi putih sambal korek pedas</td>\n",
       "      <td>(korek, ayam geprek, nasi putih)</td>\n",
       "      <td>(ayam geprek, korek, nasi putih)</td>\n",
       "      <td>(ayam geprek, korek, nasi putih)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 booking_time     order_no payment_method_name  \\\n",
       "0  2018-09-30 01:00:58.129129  F-103656423                FREE   \n",
       "1  2018-09-16 04:44:07.947744   F-94443846           PAY_LATER   \n",
       "2  2018-05-11 05:39:01.530242   F-14238997                FREE   \n",
       "3  2018-09-24 11:40:54.184264  F-100085239           PAY_LATER   \n",
       "4  2018-09-19 11:00:09.280537   F-96640563           PAY_LATER   \n",
       "\n",
       "                   merchant_name  type  \\\n",
       "0               Soto Cemorojajar  food   \n",
       "1      Warung Sate Solo Pak Hadi  food   \n",
       "2                         HokBen  food   \n",
       "3  Shukufuku Japanese StreetFood  food   \n",
       "4                    Ayam Santai  food   \n",
       "\n",
       "                                         item_list  \\\n",
       "0                                          mendoan   \n",
       "1                          sate ayam,tongseng ayam   \n",
       "2                                     hoka hemat 1   \n",
       "3                                         gyu zuke   \n",
       "4  paket ayam geprek nasi putih sambal korek pedas   \n",
       "\n",
       "                                    item_list_cln1  \\\n",
       "0                                          mendoan   \n",
       "1                          sate ayam,tongseng ayam   \n",
       "2                                       hoka hemat   \n",
       "3                                         gyu zuke   \n",
       "4  paket ayam geprek nasi putih sambal korek pedas   \n",
       "\n",
       "                                    item_list_cln2  \\\n",
       "0                                          mendoan   \n",
       "1                          sate ayam tongseng ayam   \n",
       "2                                       hoka hemat   \n",
       "3                                         gyu zuke   \n",
       "4  paket ayam geprek nasi putih sambal korek pedas   \n",
       "\n",
       "                          real_tags                      pred_tag_DL1  \\\n",
       "0                                ()                                ()   \n",
       "1       (tongseng, ayam, sate ayam)       (ayam, sate ayam, tongseng)   \n",
       "2                                ()                                ()   \n",
       "3                                ()                                ()   \n",
       "4  (korek, ayam geprek, nasi putih)  (ayam geprek, korek, nasi putih)   \n",
       "\n",
       "                       pred_tag_DL2  \n",
       "0                                ()  \n",
       "1       (ayam, sate ayam, tongseng)  \n",
       "2                                ()  \n",
       "3                                ()  \n",
       "4  (ayam geprek, korek, nasi putih)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtesting2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtesting2_upload=dtesting2[[\"order_no\",\"merchant_name\",\"type\",\"item_list\",\"real_tags\",\"pred_tag_DL1\",\"pred_tag_DL2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/alamhanz/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "dtesting2_upload[\"real_tags\"]=dtesting2_upload[\"real_tags\"].apply(lambda x:', '.join(x))\n",
    "dtesting2_upload[\"pred_tag_DL1\"]=dtesting2_upload[\"pred_tag_DL1\"].apply(lambda x:', '.join(x))\n",
    "dtesting2_upload[\"pred_tag_DL2\"]=dtesting2_upload[\"pred_tag_DL2\"].apply(lambda x:', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
