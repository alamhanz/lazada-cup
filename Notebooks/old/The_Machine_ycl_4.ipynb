{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.4 1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout, MaxPooling1D, Dense, Merge\n",
    "# from keras.layers.convolution import \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import keras as kr\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD,adam\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "print(kr.__version__,tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir_tr='training/'\n",
    "base_dir_vl='validation/'\n",
    "weight_log='weight_logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = 20000\n",
    "dtr_1=pd.read_csv(base_dir_tr+'data_manipulation_2_2_train.csv',encoding='ISO-8859-1')\n",
    "dtv_1=pd.read_csv(base_dir_vl+'data_manipulation_2_2_valid.csv',encoding='ISO-8859-1')\n",
    "dtr_2=pd.read_csv(base_dir_tr+'data_cat_tr.csv',encoding='ISO-8859-1')\n",
    "dtv_2=pd.read_csv(base_dir_vl+'data_cat_vl.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36283 11838 251\n"
     ]
    }
   ],
   "source": [
    "#### category part\n",
    "dcat_l=[]\n",
    "for cc in range(3):\n",
    "    dum=pd.get_dummies(dtr_2[dtr_2.columns[cc+1]])\n",
    "    col_i=[dtr_2.columns[cc+1]+'_'+str(i) for i in dum.columns]\n",
    "    dum.columns=col_i\n",
    "    dcat_l.append(dum)\n",
    "dcat_tr_1=pd.concat(dcat_l,axis=1)\n",
    "Xcat_tr=dcat_tr_1.as_matrix()\n",
    "\n",
    "dcat_l=[]\n",
    "for cc in range(3):\n",
    "    dum=pd.get_dummies(dtv_2[dtv_2.columns[cc+1]])\n",
    "    col_i=[dtv_2.columns[cc+1]+'_'+str(i) for i in dum.columns]\n",
    "    dum.columns=col_i\n",
    "    dcat_l.append(dum)\n",
    "dcat_tv_1=pd.concat(dcat_l,axis=1)\n",
    "Xcat_tv=dcat_tv_1.as_matrix()\n",
    "\n",
    "print(len(dcat_tr_1),len(dcat_tv_1),len(dcat_tv_1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xsd=dtr_1.rank_short_des.as_matrix()\n",
    "Xsd=np.array([ast.literal_eval(cd) for cd in Xsd])\n",
    "\n",
    "Xti=dtr_1.rank_title.as_matrix()\n",
    "Xti=np.array([ast.literal_eval(cd) for cd in Xti])\n",
    "\n",
    "ycl=dtr_1.clari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsd_v=dtv_1.rank_short_des.as_matrix()\n",
    "Xsd_v=np.array([ast.literal_eval(cd) for cd in Xsd_v])\n",
    "\n",
    "Xti_v=dtv_1.rank_title.as_matrix()\n",
    "Xti_v=np.array([ast.literal_eval(cd) for cd in Xti_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# L_Xsd=[len(x) for x in Xsd]\n",
    "# L_Xti=[len(x) for x in Xti]\n",
    "\n",
    "# dLsd=pd.DataFrame(L_Xsd)\n",
    "# dLti=pd.DataFrame(L_Xti)\n",
    "\n",
    "# dLsd[dLsd<200].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_review_length_s = 150\n",
    "max_review_length_t = 40\n",
    "Xsd = sequence.pad_sequences(Xsd, maxlen=max_review_length_s)\n",
    "Xti = sequence.pad_sequences(Xti, maxlen=max_review_length_t)\n",
    "\n",
    "Xsd_v = sequence.pad_sequences(Xsd_v, maxlen=max_review_length_s)\n",
    "Xti_v = sequence.pad_sequences(Xti_v, maxlen=max_review_length_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "for i,j,k in zip(Xsd,Xti,Xcat_tr):\n",
    "    X.append(list(k)+list(j)+list(i))\n",
    "X=np.array(X)\n",
    "\n",
    "X_v=[]\n",
    "for i,j,k in zip(Xsd_v,Xti_v,Xcat_tv):\n",
    "    X_v.append(list(k)+list(j)+list(i))\n",
    "X_v=np.array(X_v)\n",
    "\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_3_1.txt',X_v)\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_4_1.txt',X_v)\n",
    "np.savetxt(base_dir_vl+'data_input_ycl_4_2.txt',X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0][251:])==len(np.array(list(Xti[0])+list(Xsd[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0][:251])==len(np.array(list(Xcat_tr[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ycl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.943362\n",
       "0    0.056638\n",
       "Name: clari, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save('model_yco_1_2_3.h5') OKE (74.05%)\n",
    "ycl.value_counts()/ycl.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.82798054,  0.53001928])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_weight = class_weight.compute_class_weight('balanced', np.unique(ycl), ycl)\n",
    "clas_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, ycl_train, ycl_test = train_test_split(X, ycl, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train_nl=np.array([x[251:] for x in X_train])\n",
    "X_train_ct=np.array([x[:251] for x in X_train])\n",
    "\n",
    "X_test_nl=np.array([x[251:] for x in X_test])\n",
    "X_test_ct=np.array([x[:251] for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.94497\n",
       "0    0.05503\n",
       "Name: clari, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ycl_test.value_counts()/ycl_test.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    50,   135,  5013],\n",
       "       [    0,     0,     0, ...,   173,     6,   250],\n",
       "       [    0,     0,     0, ...,  4831,    21,   641],\n",
       "       ..., \n",
       "       [    0,     0,     0, ...,  1535,   233,   117],\n",
       "       [    0,     0,     0, ...,   962,    18, 14122],\n",
       "       [    1,     0,     0, ...,  2551,  3305,     0]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(X_train_nl)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    50,   135,  5013],\n",
       "       [    0,     0,     0, ...,   173,     6,   250],\n",
       "       [    0,     0,     0, ...,  4831,    21,   641],\n",
       "       ..., \n",
       "       [    0,     0,     0, ...,  1535,   233,   117],\n",
       "       [    0,     0,     0, ...,   962,    18, 14122],\n",
       "       [    0,     0,     0, ...,  2551,  3305,     0]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 4, padding=\"same\")`\n",
      "/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 4, padding=\"same\")`\n",
      "/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:36: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "#### Creating the model_1\n",
    "embedding_vecor_length = 150\n",
    "model_nl = Sequential()\n",
    "model_nl.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length_s+max_review_length_t))\n",
    "# model_nl.add(Convolution1D(64, 4, border_mode='same'))\n",
    "model_nl.add(Convolution1D(128, 4, border_mode='same'))\n",
    "model_nl.add(Convolution1D(32, 4, border_mode='same'))\n",
    "# model_nl.add(Convolution1D(16, 4, border_mode='same'))\n",
    "# model_nl.add(Convolution1D(16, 4, border_mode='same'))\n",
    "model_nl.add(Flatten())\n",
    "# model_nl.add(LSTM(80,activation='tanh', recurrent_activation='hard_sigmoid'))\n",
    "model_nl.add(Dropout(0.2))\n",
    "model_nl.add(Dense(200,activation='relu'))\n",
    "model_nl.add(Dense(200,activation='relu'))\n",
    "model_nl.add(Dense(200,activation='relu'))\n",
    "# model_nl.add(Dense(150,activation='relu'))\n",
    "model_nl.add(Dropout(0.1))\n",
    "model_nl.add(Dense(1,activation='relu'))\n",
    "\n",
    "#### Creating the model_2\n",
    "model_ct = Sequential()\n",
    "model_ct.add(Dense(70, input_shape=(251,),activation='relu'))\n",
    "model_ct.add(Dense(70, input_shape=(251,),activation='relu'))\n",
    "model_ct.add(Dense(70, input_shape=(251,),activation='relu'))\n",
    "model_ct.add(Dense(35, input_shape=(251,),activation='relu'))\n",
    "model_ct.add(Dense(35, input_shape=(251,),activation='relu'))\n",
    "model_ct.add(Dense(35, input_shape=(251,),activation='relu'))\n",
    "model_ct.add(Dense(17, input_shape=(251,),activation='relu'))\n",
    "# model_ct.add(Dense(12, input_shape=(251,),activation='relu'))\n",
    "\n",
    "model_ct.add(Dropout(0.0005))\n",
    "model_ct.add(Dense(2,activation='relu'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([model_ct,model_nl], mode='concat'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2=model\n",
    "\n",
    "# opti = SGD(lr=0.6)\n",
    "opti = adam(lr=0.0008) #0.001\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = opt)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mse'])\n",
    "model.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy','mse'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy','mse'])\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# filepath=weight_log+\"weights_best_ycl_3_1.hdf5\"\n",
    "filepath=weight_log+\"weights_best_ycl_4_2.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 251), (None, 190)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25398, 251) (25398, 190)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ct.shape,X_train_nl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25398 samples, validate on 10885 samples\n",
      "Epoch 1/200\n",
      "25300/25398 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9414 - mean_squared_error: 0.0527Epoch 00000: val_mean_squared_error improved from inf to 0.04494, saving model to weight_logs/weights_best_ycl_4_2.hdf5\n",
      "25398/25398 [==============================] - 95s - loss: 0.1959 - acc: 0.9415 - mean_squared_error: 0.0526 - val_loss: 0.1659 - val_acc: 0.9450 - val_mean_squared_error: 0.0449\n",
      "Epoch 2/200\n",
      "25300/25398 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9426 - mean_squared_error: 0.0424Epoch 00001: val_mean_squared_error did not improve\n",
      "25398/25398 [==============================] - 91s - loss: 0.1476 - acc: 0.9427 - mean_squared_error: 0.0423 - val_loss: 0.1868 - val_acc: 0.9450 - val_mean_squared_error: 0.0469\n",
      "Epoch 3/200\n",
      " 8600/25398 [=========>....................] - ETA: 54s - loss: 0.1114 - acc: 0.9451 - mean_squared_error: 0.0335"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-8509f035d999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_ct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_nl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclas_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_ct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_nl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycl_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([X_train_ct,X_train_nl],ycl_train, class_weight=clas_weight, validation_data=([X_test_ct,X_test_nl],ycl_test),callbacks=callbacks_list, epochs=200, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model2.load_weights(weight_log+\"weights_best_ycl_3_1.hdf5\")\n",
    "# model2.load_weights(weight_log+\"weights_best_ycl_4_1.hdf5\")\n",
    "model2.load_weights(weight_log+\"weights_best_ycl_4_2.hdf5\")\n",
    "model2.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10880/10885 [============================>.] - ETA: 0sAccuracy: 94.50%\n",
      "MSE_class :  0.0550298576022\n",
      "MSE_prob :  0.0449408995951\n"
     ]
    }
   ],
   "source": [
    "#### Evaluation on the test set\n",
    "ycl_predc=model2.predict_classes([X_test_ct,X_test_nl])\n",
    "ycl_predp=model2.predict([X_test_ct,X_test_nl])\n",
    "\n",
    "ycl_predc=[i[0] for i in ycl_predc]\n",
    "ycl_predp=[i[0] for i in ycl_predp]\n",
    "\n",
    "scores = model2.evaluate([X_test_ct,X_test_nl], ycl_test, verbose=0)\n",
    "mse_c=mse(ycl_test,ycl_predc)\n",
    "mse_p=mse(ycl_test,ycl_predp)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100)) \n",
    "print(\"MSE_class : \",mse_c)\n",
    "print(\"MSE_prob : \",mse_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_nl.save('model_ycl_4_1(1).h5') #<-0.45227\n",
    "# model_ct.save('model_ycl_4_1(2).h5')\n",
    "\n",
    "model_nl.save('model_ycl_4_2(1).h5') #<-0.04494\n",
    "model_ct.save('model_ycl_4_2(2).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/keras/models.py:248: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/dataanalysis/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_4_2.txt')\n",
    "\n",
    "ycl_model_1=load_model('model_ycl_4_2(1).h5')\n",
    "ycl_model_2=load_model('model_ycl_4_2(2).h5')\n",
    "ycl_model = Sequential()\n",
    "ycl_model.add(Merge([ycl_model_2,ycl_model_1], mode='concat'))\n",
    "ycl_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "ycl_model.load_weights(weight_log+\"weights_best_ycl_4_2.hdf5\")\n",
    "ycl_model.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vl_nl=np.array([x[251:] for x in X_vl])\n",
    "X_vl_ct=np.array([x[:251] for x in X_vl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ycl_predp=ycl_model.predict([X_vl_ct,X_vl_nl])\n",
    "ycl_predp=[i[0] for i in ycl_predp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clarity_valid.predict','w') as fcl:\n",
    "    for pp in ycl_predp:\n",
    "        fcl.write(str(pp))\n",
    "        fcl.write('\\n')\n",
    "fcl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3.5]",
   "language": "python",
   "name": "conda-env-python3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
