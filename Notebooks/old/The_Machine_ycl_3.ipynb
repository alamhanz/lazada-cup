{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout,MaxPooling1D\n",
    "# from keras.layers.convolution import \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import keras as kr\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "kr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir_tr='training/'\n",
    "base_dir_vl='validation/'\n",
    "weight_log='weight_logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = 20000\n",
    "dtr_1=pd.read_csv(base_dir_tr+'data_manipulation_2_2_train.csv',encoding='ISO-8859-1')\n",
    "dtv_1=pd.read_csv(base_dir_vl+'data_manipulation_2_2_valid.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xsd=dtr_1.rank_short_des.as_matrix()\n",
    "Xsd=np.array([ast.literal_eval(cd) for cd in Xsd])\n",
    "\n",
    "Xti=dtr_1.rank_title.as_matrix()\n",
    "Xti=np.array([ast.literal_eval(cd) for cd in Xti])\n",
    "\n",
    "ycl=dtr_1.clari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsd_v=dtv_1.rank_short_des.as_matrix()\n",
    "Xsd_v=np.array([ast.literal_eval(cd) for cd in Xsd_v])\n",
    "\n",
    "Xti_v=dtv_1.rank_title.as_matrix()\n",
    "Xti_v=np.array([ast.literal_eval(cd) for cd in Xti_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_review_length_s = 150\n",
    "max_review_length_t = 40\n",
    "Xsd = sequence.pad_sequences(Xsd, maxlen=max_review_length_s)\n",
    "Xti = sequence.pad_sequences(Xti, maxlen=max_review_length_t)\n",
    "\n",
    "Xsd_v = sequence.pad_sequences(Xsd_v, maxlen=max_review_length_s)\n",
    "Xti_v = sequence.pad_sequences(Xti_v, maxlen=max_review_length_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "for i,j in zip(Xsd,Xti):\n",
    "    X.append(list(j)+list(i))\n",
    "X=np.array(X)\n",
    "\n",
    "X_v=[]\n",
    "for i,j in zip(Xsd_v,Xti_v):\n",
    "    X_v.append(list(j)+list(i))\n",
    "X_v=np.array(X_v)\n",
    "\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_3_1.txt',X_v)\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_3_2.txt',X_v)\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_3_3.txt',X_v)\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_3_4.txt',X_v)\n",
    "np.savetxt(base_dir_vl+'data_input_ycl_3_5.txt',X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yco model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model_yco_1_2_3.h5') OKE (74.05%)\n",
    "ycl.value_counts()/ycl.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_weight = class_weight.compute_class_weight('balanced', np.unique(ycl), ycl)\n",
    "clas_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, ycl_train, ycl_test = train_test_split(X, ycl, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Creating the model_1\n",
    "np.random.seed(21)\n",
    "\n",
    "# Using embedding from Keras\n",
    "embedding_vecor_length = 150\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length_s+max_review_length_t))\n",
    "\n",
    "# model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "# model.add(MaxPooling1D(2))\n",
    "model.add(LSTM(80))\n",
    "# model.add(Flatten())\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(300,activation='sigmoid'))\n",
    "# model.add(Dense(300,activation='sigmoid'))\n",
    "# model.add(Dense(400,activation='sigmoid'))\n",
    "# model.add(Dense(500,activation='sigmoid'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2=model\n",
    "\n",
    "# Log to tensorboard\n",
    "# tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mse'])\n",
    "\n",
    "# checkpoint\n",
    "# filepath=weight_log+\"weights_best_ycl_3_1.hdf5\"\n",
    "# filepath=weight_log+\"weights_best_ycl_3_2.hdf5\"\n",
    "# filepath=weight_log+\"weights_best_ycl_3_3.hdf5\"\n",
    "# filepath=weight_log+\"weights_best_ycl_3_4.hdf5\"\n",
    "filepath=weight_log+\"weights_best_ycl_3_5.hdf5\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 190) (25398, 190)\n"
     ]
    }
   ],
   "source": [
    "# model.summary()\n",
    "print(model.input_shape,X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25398 samples, validate on 10885 samples\n",
      "Epoch 1/20\n",
      "25300/25398 [============================>.] - ETA: 2s - loss: 0.2040 - acc: 0.9426 - mean_squared_error: 0.0524Epoch 00000: val_mean_squared_error improved from inf to 0.04804, saving model to weight_logs/weights_best_ycl_3_5.hdf5\n",
      "25398/25398 [==============================] - 794s - loss: 0.2042 - acc: 0.9427 - mean_squared_error: 0.0523 - val_loss: 0.1827 - val_acc: 0.9450 - val_mean_squared_error: 0.0480\n",
      "Epoch 2/20\n",
      "25300/25398 [============================>.] - ETA: 2s - loss: 0.1621 - acc: 0.9429 - mean_squared_error: 0.0458Epoch 00001: val_mean_squared_error did not improve\n",
      "25398/25398 [==============================] - 733s - loss: 0.1620 - acc: 0.9430 - mean_squared_error: 0.0458 - val_loss: 0.1907 - val_acc: 0.9444 - val_mean_squared_error: 0.0500\n",
      "Epoch 3/20\n",
      "25300/25398 [============================>.] - ETA: 2s - loss: 0.1237 - acc: 0.9530 - mean_squared_error: 0.0363Epoch 00002: val_mean_squared_error did not improve\n",
      "25398/25398 [==============================] - 817s - loss: 0.1239 - acc: 0.9528 - mean_squared_error: 0.0363 - val_loss: 0.2270 - val_acc: 0.9362 - val_mean_squared_error: 0.0541\n",
      "Epoch 4/20\n",
      " 3200/25398 [==>...........................] - ETA: 619s - loss: 0.0895 - acc: 0.9631 - mean_squared_error: 0.0265"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-87db602f9a32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mycl_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mycl_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclas_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2229\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, ycl_train, validation_data=(X_test,ycl_test),callbacks=callbacks_list, epochs=20, batch_size=100, verbose=1,class_weight = clas_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model2.load_weights(weight_log+\"weights_best_ycl_3_1.hdf5\")\n",
    "# model2.load_weights(weight_log+\"weights_best_ycl_3_2.hdf5\")\n",
    "# model2.load_weights(weight_log+\"weights_best_ycl_3_3.hdf5\")\n",
    "# model2.load_weights(weight_log+\"weights_best_ycl_3_4.hdf5\")\n",
    "model2.load_weights(weight_log+\"weights_best_ycl_3_5.hdf5\")\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluation on the test set\n",
    "ycl_predc=model2.predict_classes(X_test)\n",
    "ycl_predp=model2.predict(X_test)\n",
    "\n",
    "ycl_predc=[i[0] for i in ycl_predc]\n",
    "ycl_predp=[i[0] for i in ycl_predp]\n",
    "\n",
    "scores = model2.evaluate(X_test, ycl_test, verbose=0)\n",
    "mse_c=mse(ycl_test,ycl_predc)\n",
    "mse_p=mse(ycl_test,ycl_predp)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100)) \n",
    "print(\"MSE_class : \",mse_c)\n",
    "print(\"MSE_prob : \",mse_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('model_ycl_2_1_2.h5') <-3 epoch 0.04628\n",
    "# model2.save('model_ycl_3_1.h5') #<- 0.0468\n",
    "# model2.save('model_ycl_3_2.h5') #<- 0.04676\n",
    "# model2.save('model_ycl_3_3.h5') #<-0.04609\n",
    "# model2.save('model_ycl_3_4.h5') #<-0.04567\n",
    "model2.save('model_ycl_3_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### model.save('model_ycl_3_3.h5')\n",
    "np.random.seed(21)\n",
    "\n",
    "# Using embedding from Keras\n",
    "embedding_vecor_length = 150\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length_s+max_review_length_t))\n",
    "\n",
    "# model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model.add(Convolution1D(16, 3, border_mode='same'))\n",
    "# model.add(Convolution1D(8, 3, border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(200,activation='sigmoid'))\n",
    "model.add(Dense(200,activation='sigmoid'))\n",
    "# model.add(Dense(200,activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2=model\n",
    "\n",
    "# Log to tensorboard\n",
    "# tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_3_1.txt')\n",
    "# ycl_model=load_model('model_ycl_3_1.h5')\n",
    "\n",
    "# X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_3_2.txt')\n",
    "# ycl_model=load_model('model_ycl_3_2.h5')\n",
    "\n",
    "# X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_3_3.txt')\n",
    "# ycl_model=load_model('model_ycl_3_3.h5')\n",
    "\n",
    "# X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_3_4.txt')\n",
    "# ycl_model=load_model('model_ycl_3_4.h5')\n",
    "\n",
    "X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_3_5.txt')\n",
    "ycl_model=load_model('model_ycl_3_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ..., \n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v==X_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ycl_predp=ycl_model.predict(X_vl)\n",
    "ycl_predp=[i[0] for i in ycl_predp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clarity_valid.predict','w') as fcl:\n",
    "    for pp in ycl_predp:\n",
    "        fcl.write(str(pp))\n",
    "        fcl.write('\\n')\n",
    "fcl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:snakes3_gpu]",
   "language": "python",
   "name": "conda-env-snakes3_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
