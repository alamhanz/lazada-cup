{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.4 1.0.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout, MaxPooling1D, Dense, Merge\n",
    "# from keras.layers.convolution import \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import keras as kr\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD, adam\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "print(kr.__version__,tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir_tr='training/'\n",
    "base_dir_vl='validation/'\n",
    "weight_log='weight_logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = 20000\n",
    "dtr_1=pd.read_csv(base_dir_tr+'data_manipulation_2_2_train.csv',encoding='ISO-8859-1')\n",
    "dvl_1=pd.read_csv(base_dir_vl+'data_manipulation_2_2_valid.csv',encoding='ISO-8859-1')\n",
    "dtr_2=pd.read_csv(base_dir_tr+'length_string_2.csv',encoding='ISO-8859-1')\n",
    "dvl_2=pd.read_csv(base_dir_vl+'length_string_2.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr=pd.merge(dtr_1,dtr_2,on='sku_id',how='left')\n",
    "Xl_tr=dtr[['len_title_des','len_short_des','price_rupiah_st']].as_matrix()\n",
    "dvl=pd.merge(dvl_1,dvl_2,on='sku_id',how='left')\n",
    "Xl_vl=dvl[['len_title_des','len_short_des','price_rupiah_st']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xsd=dtr.rank_short_des.as_matrix()\n",
    "Xsd=np.array([ast.literal_eval(cd) for cd in Xsd])\n",
    "\n",
    "Xti=dtr.rank_title.as_matrix()\n",
    "Xti=np.array([ast.literal_eval(cd) for cd in Xti])\n",
    "\n",
    "yco=dtr_1.conci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsd_v=dvl.rank_short_des.as_matrix()\n",
    "Xsd_v=np.array([ast.literal_eval(cd) for cd in Xsd_v])\n",
    "\n",
    "Xti_v=dvl.rank_title.as_matrix()\n",
    "Xti_v=np.array([ast.literal_eval(cd) for cd in Xti_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_review_length_s = 150\n",
    "max_review_length_t = 40\n",
    "Xsd = sequence.pad_sequences(Xsd, maxlen=max_review_length_s)\n",
    "Xti = sequence.pad_sequences(Xti, maxlen=max_review_length_t)\n",
    "\n",
    "Xsd_v = sequence.pad_sequences(Xsd_v, maxlen=max_review_length_s)\n",
    "Xti_v = sequence.pad_sequences(Xti_v, maxlen=max_review_length_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "for i,j,k in zip(Xsd,Xti,Xl_tr):\n",
    "    X.append(list(k)+list(j)+list(i))\n",
    "X=np.array(X)\n",
    "\n",
    "X_v=[]\n",
    "for i,j,k in zip(Xsd_v,Xti_v,Xl_vl):\n",
    "    X_v.append(list(k)+list(j)+list(i))\n",
    "X_v=np.array(X_v)\n",
    "\n",
    "# np.savetxt(base_dir_vl+'data_input_ycl_3_1.txt',X_v)\n",
    "np.savetxt(base_dir_vl+'data_input_yco_5_1.txt',X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0][3:])==len(np.array(list(Xti[0])+list(Xsd[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0][:3])==len(np.array(list(Xl_tr[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.00000000e+00,   1.50000000e+01,   5.20854665e-05])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yco model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.685335\n",
       "0    0.314665\n",
       "Name: conci, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save('model_yco_1_2_3.h5') OKE (74.05%)\n",
    "yco.value_counts()/yco.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, yco_train, yco_test = train_test_split(X, yco, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train_nl=np.array([x[3:] for x in X_train])\n",
    "X_train_ct=np.array([x[:3] for x in X_train])\n",
    "\n",
    "X_test_nl=np.array([x[3:] for x in X_test])\n",
    "X_test_ct=np.array([x[:3] for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.686082\n",
       "0    0.313918\n",
       "Name: conci, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yco_test.value_counts()/yco_test.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.00000000e+00,   2.50000000e+01,   1.06085461e-04, ...,\n",
       "          5.00000000e+01,   1.35000000e+02,   5.01300000e+03],\n",
       "       [  1.30000000e+01,   2.00000000e+01,   2.56094165e-05, ...,\n",
       "          1.73000000e+02,   6.00000000e+00,   2.50000000e+02],\n",
       "       [  1.50000000e+01,   1.60000000e+01,   2.20754698e-05, ...,\n",
       "          4.83100000e+03,   2.10000000e+01,   6.41000000e+02],\n",
       "       ..., \n",
       "       [  1.50000000e+01,   2.20000000e+01,   6.80854648e-05, ...,\n",
       "          1.53500000e+03,   2.33000000e+02,   1.17000000e+02],\n",
       "       [  1.30000000e+01,   2.30000000e+01,   6.99788815e-05, ...,\n",
       "          9.62000000e+02,   1.80000000e+01,   1.41220000e+04],\n",
       "       [  1.20000000e+01,   1.50000000e+01,   8.20854633e-05, ...,\n",
       "          2.55100000e+03,   3.30500000e+03,   0.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(X_train_nl)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          5.00000000e+01,   1.35000000e+02,   5.01300000e+03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.73000000e+02,   6.00000000e+00,   2.50000000e+02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          4.83100000e+03,   2.10000000e+01,   6.41000000e+02],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.53500000e+03,   2.33000000e+02,   1.17000000e+02],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          9.62000000e+02,   1.80000000e+01,   1.41220000e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          2.55100000e+03,   3.30500000e+03,   0.00000000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "C:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "C:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "C:\\Users\\Aska\\Anaconda2\\envs\\snakes3_gpu\\lib\\site-packages\\ipykernel\\__main__.py:37: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "#### Creating the model_1\n",
    "embedding_vecor_length = 100\n",
    "model_nl = Sequential()\n",
    "model_nl.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length_s+max_review_length_t))\n",
    "# model_nl.add(Convolution1D(64, 4, border_mode='same'))\n",
    "# model_nl.add(LSTM(8))\n",
    "model_nl.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_nl.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_nl.add(Convolution1D(32, 3, border_mode='same'))\n",
    "\n",
    "# model_nl.add(Convolution1D(16, 3, border_mode='same'))\n",
    "model_nl.add(Flatten())\n",
    "model_nl.add(Dropout(0.2))\n",
    "# model_nl.add(Dense(300,activation='relu'))\n",
    "model_nl.add(Dense(300,activation='relu'))\n",
    "model_nl.add(Dense(300,activation='relu'))\n",
    "model_nl.add(Dense(100,activation='relu'))\n",
    "model_nl.add(Dense(100,activation='relu'))\n",
    "\n",
    "\n",
    "# model_nl.add(Dense(100,activation='relu'))\n",
    "model_nl.add(Dropout(0.1))\n",
    "model_nl.add(Dense(20,activation='relu'))\n",
    "\n",
    "#### Creating the model_2\n",
    "model_ct = Sequential()\n",
    "model_ct.add(Dense(100, input_shape=(3,),activation='relu'))\n",
    "model_ct.add(Dense(100,activation='relu'))\n",
    "model_ct.add(Dense(50,activation='relu'))\n",
    "model_ct.add(Dense(50,activation='relu'))\n",
    "model_ct.add(Dropout(0.1))\n",
    "model_ct.add(Dense(20,activation='relu'))\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Merge([model_ct,model_nl], mode='concat'))\n",
    "model.add(Merge([model_ct,model_nl], mode='dot'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(25,activation='relu'))\n",
    "model.add(Dense(25,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2=model\n",
    "\n",
    "# opt = SGD(lr=0.5)\n",
    "opt= adam(lr=0.001)\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = opt)\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['accuracy','mse'])\n",
    "# model.compile(loss='mse', optimizer=adam1, metrics=['accuracy','mse'])\n",
    "\n",
    "# model.compile(loss='mse', optimizer=opt, metrics=['accuracy','mse'])\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# filepath=weight_log+\"weights_best_ycl_3_1.hdf5\"\n",
    "filepath=weight_log+\"weights_best_yco_5_1.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 3), (None, 190)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25398, 3) (25398, 190)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ct.shape,X_train_nl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25398 samples, validate on 10885 samples\n",
      "Epoch 1/100\n",
      "25300/25398 [============================>.] - ETA: 1s - loss: 0.1773 - acc: 0.7444 - mean_squared_error: 0.1773Epoch 00000: val_mean_squared_error improved from inf to 0.14660, saving model to weight_logs/weights_best_yco_5_1.hdf5\n",
      "25398/25398 [==============================] - 353s - loss: 0.1772 - acc: 0.7447 - mean_squared_error: 0.1772 - val_loss: 0.1466 - val_acc: 0.8090 - val_mean_squared_error: 0.1466\n",
      "Epoch 2/100\n",
      "25300/25398 [============================>.] - ETA: 1s - loss: 0.1264 - acc: 0.8319 - mean_squared_error: 0.1264Epoch 00001: val_mean_squared_error improved from 0.14660 to 0.13776, saving model to weight_logs/weights_best_yco_5_1.hdf5\n",
      "25398/25398 [==============================] - 347s - loss: 0.1262 - acc: 0.8322 - mean_squared_error: 0.1262 - val_loss: 0.1378 - val_acc: 0.8198 - val_mean_squared_error: 0.1378\n",
      "Epoch 3/100\n",
      "25300/25398 [============================>.] - ETA: 1s - loss: 0.1021 - acc: 0.8680 - mean_squared_error: 0.1021Epoch 00002: val_mean_squared_error did not improve\n",
      "25398/25398 [==============================] - 345s - loss: 0.1020 - acc: 0.8681 - mean_squared_error: 0.1020 - val_loss: 0.1443 - val_acc: 0.8130 - val_mean_squared_error: 0.1443\n",
      "Epoch 4/100\n",
      "25300/25398 [============================>.] - ETA: 1s - loss: 0.0876 - acc: 0.8885 - mean_squared_error: 0.0876Epoch 00003: val_mean_squared_error did not improve\n",
      "25398/25398 [==============================] - 349s - loss: 0.0877 - acc: 0.8885 - mean_squared_error: 0.0877 - val_loss: 0.1506 - val_acc: 0.8082 - val_mean_squared_error: 0.1506\n",
      "Epoch 5/100\n",
      "14500/25398 [================>.............] - ETA: 135s - loss: 0.0766 - acc: 0.9059 - mean_squared_error: 0.0766"
     ]
    }
   ],
   "source": [
    "model.fit([X_train_ct,X_train_nl],yco_train, validation_data=([X_test_ct,X_test_nl],yco_test),callbacks=callbacks_list, epochs=100, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model2.load_weights(weight_log+\"weights_best_ycl_3_1.hdf5\")\n",
    "model2.load_weights(weight_log+\"weights_best_yco_5_1.hdf5\")\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluation on the test set\n",
    "ycl_predc=model2.predict_classes(X_test)\n",
    "ycl_predp=model2.predict(X_test)\n",
    "\n",
    "ycl_predc=[i[0] for i in ycl_predc]\n",
    "ycl_predp=[i[0] for i in ycl_predp]\n",
    "\n",
    "scores = model2.evaluate(X_test, ycl_test, verbose=0)\n",
    "mse_c=mse(ycl_test,ycl_predc)\n",
    "mse_p=mse(ycl_test,ycl_predp)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100)) \n",
    "print(\"MSE_class : \",mse_c)\n",
    "print(\"MSE_prob : \",mse_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model2.save('model_yco_3_3.h5') # MSE prob 82.09% 0.1310365\n",
    "# model2.save('model_yco_3_4.h5') # 82.35%     0.13095322\n",
    "model2.save('model_yco_5_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### model.save('model_ycl_3_3.h5')\n",
    "np.random.seed(21)\n",
    "\n",
    "# Using embedding from Keras\n",
    "embedding_vecor_length = 150\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length_s+max_review_length_t))\n",
    "\n",
    "# model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model.add(Convolution1D(16, 3, border_mode='same'))\n",
    "# model.add(Convolution1D(8, 3, border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(200,activation='sigmoid'))\n",
    "model.add(Dense(200,activation='sigmoid'))\n",
    "# model.add(Dense(200,activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2=model\n",
    "\n",
    "# Log to tensorboard\n",
    "# tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_3_4.txt')\n",
    "# ycl_model=load_model('model_ycl_3_4.h5')\n",
    "\n",
    "X_vl=np.loadtxt(base_dir_vl+'data_input_ycl_4_1.txt')\n",
    "ycl_model=load_model('model_ycl_4_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ..., \n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v==X_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ycl_predp=ycl_model.predict(X_vl)\n",
    "ycl_predp=[i[0] for i in ycl_predp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clarity_valid.predict','w') as fcl:\n",
    "    for pp in ycl_predp:\n",
    "        fcl.write(str(pp))\n",
    "        fcl.write('\\n')\n",
    "fcl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:snakes3_gpu]",
   "language": "python",
   "name": "conda-env-snakes3_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
